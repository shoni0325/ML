{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.linear_model.LogisticRegression\n",
    "\n",
    "* _class_ sklearn.linear_model.LogisticRegression(_penalty='l2'_,  _*_,  _dual=False_,  _tol=0.0001_,  _C=1.0_,  _fit_intercept=True_,  _intercept_scaling=1_,  _class_weight=None_,  _random_state=None_,  _solver='lbfgs'_,  _max_iter=100_,  _multi_class='auto'_,  _verbose=0_,  _warm_start=False_,  _n_jobs=None_,  _l1_ratio=None_)[[source]](https://github.com/scikit-learn/scikit-learn/blob/364c77e04/sklearn/linear_model/_logistic.py#L783)[](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression \"Permalink to this definition\")\n",
    "\n",
    "\n",
    "* **solver**\n",
    "     : {‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "     - Algorithm to use in the optimization problem. Default is ‘lbfgs’. To choose a solver, you might want to consider the following aspects:\n",
    "     \n",
    "     > -   For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones;\n",
    "     >     \n",
    "     > -   For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss;\n",
    "     >     \n",
    "     > -   ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "     >     \n",
    "     > -   ‘newton-cholesky’ is a good choice for  `n_samples`  >>  `n_features`, especially with one-hot encoded categorical features with rare categories. Note that it is limited to binary classification and the one-versus-rest reduction for multiclass classification. Be aware that the memory usage of this solver has a quadratic dependency on  `n_features`  because it explicitly computes the Hessian matrix.\n",
    ">\n",
    "\n",
    "* **multi_class**\n",
    "     : {‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "\n",
    "     If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution,  _even when the data is binary_. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.\n",
    "\n",
    "     New in version 0.18: Stochastic Average Gradient descent solver for ‘multinomial’ case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위스콘신 유방암 데이터 불러오기\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# StandardScaler()로 평균이 0, 분산 1로 데이터 분포도 변환\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, cancer.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.977\n",
      "roc_auc : 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 학습 및 예측 수행\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "# accuracy와 roc_auc 측정\n",
    "print(f'accuracy : {accuracy_score(y_test, lr_preds):0.3f}')\n",
    "print(f'roc_auc : {roc_auc_score(y_test, lr_preds):0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터 : {'C': 1, 'penalty': 'l2'}, 최적 평균 정확도 : 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'penalty' : ['l2', 'l1'],\n",
    "          'C' : [0.01, 0.1, 1, 1, 5, 10]}\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3)\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "\n",
    "print(f'최적 하이퍼 파라미터 : {grid_clf.best_params_}, 최적 평균 정확도 : {grid_clf.best_score_:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LogisticRegression(multi_class='auto') 가 기본값\n",
    "\n",
    "파라미터 조정을 통해 값이 달라지는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.977\n",
      "roc_auc : 0.972\n"
     ]
    }
   ],
   "source": [
    "# multi_class='ovr'\n",
    "lr_clf = LogisticRegression(multi_class='ovr')\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "print(f'accuracy : {accuracy_score(y_test, lr_preds):0.3f}')\n",
    "print(f'roc_auc : {roc_auc_score(y_test, lr_preds):0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.953\n",
      "roc_auc : 0.953\n"
     ]
    }
   ],
   "source": [
    "# multi_class='multinomial'\n",
    "lr_clf = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "print(f'accuracy : {accuracy_score(y_test, lr_preds):0.3f}')\n",
    "print(f'roc_auc : {roc_auc_score(y_test, lr_preds):0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
